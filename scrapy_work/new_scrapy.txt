安装scrapy框架
1.安装scrapy：通过pip install scrapy安装
2.如果在Windows下，还需要安装pypwin32，通过pip install pypwin32

创建爬虫：
创建项目："scrapy startproject[爬虫名字]"
创建爬虫：进入所在项目，执行命令："scrapy genspider[爬虫名字][爬虫的域名]"

项目结构：

1.items.py:用来存放爬虫爬取下来数据的模型
2.middlewares.py：用来存放各种中间文件
3.pipelines.py：用来将items的模型存储到本地磁盘
4、seetings.py：本爬虫的配置信息（比如请求头、多久发一次请求、ip代理池）
5.scrapy.cfg：项目的配置文件
6.spiders包：以后的爬虫都存放在这个里面


爬取及运行方法：
1.修改settings,里面的，ROBOTSTXT_OBEY改为false。修改请求头DEFAULT_REQUEST_HEADERS。
2.在spider里面写主爬虫程序。在parse里写爬虫程序。
3.通过scrapy crawl qsbk_spider运行程序。
4.也可在文件根目录建一个start文件通过命令行运行，代码如下
from scrapy import cmdline

cmdline.execute(['scrapy','crawl','qsbk_spider'])
